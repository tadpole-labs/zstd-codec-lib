{
  "version": 3,
  "sources": ["../queue.ts", "../shared.ts", "../zstd-wasm.ts"],
  "sourcesContent": [
    "/// @author 101arrowz (https://github.com/101arrowz/fzstd/blob/master/src/index.ts)\nexport interface DZstdState {\n  d: number;  // dictionary ID\n  u: number;  // uncompressed size\n  e: number;  // window size\n}\n\nexport const rb = /* @__PURE__ */ (d: Uint8Array, b: number, n: number) => {\n  let i = 0, o = 0;\n  for (; i < n; ++i) o |= d[b++] << (i << 3);\n  return o;\n};\n\nexport const _fss = (dat: Uint8Array): number => {\n  const flg = dat[4];\n  const ss = (flg >> 5) & 1, df = flg & 3, fcf = flg >> 6;\n  // @ts-expect-error\n  const fss = rb(dat, (6 - ss) + df == 3 ? 4 : df, fcf ? (1 << fcf) : ss) + ((fcf == 1) && 256);\n  return fss\n}\n\n// Read Zstandard frame header\nexport const rzfh = /* @__PURE__ */ (dat: Uint8Array): number | DZstdState => {\n  const n3 = dat[0] | (dat[1] << 8) | (dat[2] << 16);\n  if (n3 == 0x2FB528 && dat[3] == 253) {\n    // Zstandard frame\n    const flg = dat[4];\n    // single segment, checksum, dict flag, frame content flag\n    const ss = (flg >> 5) & 1, df = flg & 3, fcf = flg >> 6;\n    if (flg & 8) throw new Error('invalid zstd data'); // Reserved bit check\n    // byte\n    let bt = 6 - ss;\n    // dict bytes\n    const db = df == 3 ? 4 : df;\n    // dictionary id\n    const di = rb(dat, bt, db);\n    // @ts-expect-error\n    const fss = rb(dat, bt + db, fcf ? (1 << fcf) : ss) + ((fcf == 1) && 256);\n    // window size\n    let ws = fss;\n    if (!ss) {\n      // window descriptor\n      const wb = 1 << (10 + (dat[5] >> 3));\n      ws = wb + (wb >> 3) * (dat[5] & 7);\n    }\n    if (ws > 2145386496) throw new Error('window size too large');\n    return {\n      d: di,\n      e: ws,\n      u: fss\n    };\n  }\n  throw new Error('invalid zstd data');\n};\n",
    "import ZstdDecoder from './zstd-wasm.js';\nimport type { StreamResult, ZstdOptions } from './types.js';\nimport { rzfh, DZstdState } from './queue.js';\n\nexport { default as ZstdDecoder } from './zstd-wasm.js';\n\n// WASM loader - assigned by each entry point\nexport const _internal = {\n  _loader: null as ((wasmPath?: string) => WebAssembly.Module | Promise<WebAssembly.Module>) | null,\n  bufferSizes: { \n    maxSrcSize: 64 * 1024 * 1024,    // 64MB\n    maxDstSize: 128 * 1024 * 1024    // 128MB\n  },\n  dictionaries: [] as string[]\n};\n\n// Dictionary ID -> Map of decoder index to decoder\nconst decoderPools = new Map<number, Map<number, ZstdDecoder>>();\n// Dictionary ID -> array of pool locks\nconst poolLocks = new Map<number, boolean[]>();\nlet isInitialized = false;\nlet cachedModule: WebAssembly.Module;\n\nconst loadedDictionaries = new Map<number, Uint8Array>();\n\nfunction /* @__PURE__ */ _createDecoderInstance(dictionary?: Uint8Array | ArrayBuffer | Request | string): ZstdDecoder {\n  const dict = dictionary instanceof Uint8Array ? dictionary :\n               dictionary instanceof ArrayBuffer ? new Uint8Array(dictionary) :\n               undefined;\n  \n  const decoder = new ZstdDecoder({ ..._internal.bufferSizes, dictionary: dict });\n  decoder.init(cachedModule);\n  return decoder;\n}\n\nexport const setupZstdDecoder = /* @__PURE__ */ async (options: {\n  maxSrcSize?: number;\n  maxDstSize?: number;\n  dictionaries?: string[];  // URLs or data:uris\n}) => {\n  if (options.maxSrcSize) _internal.bufferSizes.maxSrcSize = options.maxSrcSize;\n  if (options.maxDstSize) _internal.bufferSizes.maxDstSize = options.maxDstSize;\n  \n  if (options.dictionaries) {\n    for (const url of options.dictionaries) {\n      const dict = await loadResource(url);\n      const id = _getDictId(dict);\n      if (id > 0) loadedDictionaries.set(id, dict);\n    }\n  }\n};\n\nexport function _concatUint8Arrays(arrays: Uint8Array[], ol: number): Uint8Array {\n  if (arrays.length === 1) return arrays[0];\n  const buf = new Uint8Array(ol);\n  for (let i = 0, b = 0; i < arrays.length; ++i) {\n    const chk = arrays[i];\n    buf.set(chk, b);\n    b += chk.length;\n  }\n  return buf;\n}\n\nasync function _acquireDecoder(dictId: number = 0, options?: ZstdOptions): Promise<[ZstdDecoder, number, number]> {\n  // All busy, create new one\n  if (!cachedModule) {\n    const module = _internal._loader!();\n    cachedModule = module instanceof Promise ? await module : module;\n  }\n\n  // Ensure pool exists for this dictionary ID\n  if (!decoderPools.has(dictId)) {\n    decoderPools.set(dictId, new Map());\n    poolLocks.set(dictId, []);\n  }\n  \n  const pool = decoderPools.get(dictId)!;\n  const locks = poolLocks.get(dictId)!;\n  \n  // Try to find an available decoder\n  for (let i = 0; i < locks.length; i++) {\n    if (!locks[i]) {\n      locks[i] = true;\n      return [pool.get(i)!, i, dictId];\n    }\n  }\n  \n  const dictionary = options?.dictionary || loadedDictionaries.get(dictId);\n  const decoder = _createDecoderInstance(dictId > 0 ? dictionary : undefined);\n  \n  // Limit pool size to 3 per dictionary\n  if (locks.length >= 3) return [decoder, -1, dictId];\n  \n  const newIdx = locks.length;\n  pool.set(newIdx, decoder);\n  locks.push(true);\n  return [decoder, newIdx, dictId];\n}\n\nfunction _releaseDecoder(idx: number, dictId: number): void {\n  const locks = poolLocks.get(dictId);\n  if (locks) locks[idx] = false;\n}\n\nexport function _pushToPool(decoder: ZstdDecoder, module: WebAssembly.Module, dictId: number = 0): void {\n  cachedModule = module;\n  if (!decoderPools.has(dictId)) {\n    decoderPools.set(dictId, new Map());\n    poolLocks.set(dictId, []);\n  }\n  const pool = decoderPools.get(dictId)!;\n  const locks = poolLocks.get(dictId)!;\n  pool.set(locks.length, decoder);\n  locks.push(false);\n}\n\n/**\n * Load resource as Uint8Array (handles all input types)\n */\nconst loadResource = /* @__PURE__ */ async (resource: Uint8Array | ArrayBuffer | Request | string): Promise<Uint8Array> => {\n  if (resource instanceof Uint8Array) return resource;\n  if (resource instanceof ArrayBuffer) return new Uint8Array(resource);\n  const response = await fetch(resource);\n  return new Uint8Array(await response.arrayBuffer());\n};\n\n/**\n * Get dictionary ID from frame header\n */\nconst _getDictId = /* @__PURE__ */ (input: Uint8Array): number => {\n  if (input.length < 6) return 0;\n  try {\n    const header = rzfh(input);\n    const id = typeof header === 'object' ? header.d : 0;\n    if (id > 0) loadedDictionaries.set(id, input);\n    return id;\n  } catch {\n    return 0;\n  }\n};\n\n/**\n * Create a decoder instance\n */\nexport const createDecoder = /* @__PURE__ */ async (options: ZstdOptions = {}): Promise<ZstdDecoder> => {\n  if (!isInitialized) {\n    const module = _internal._loader!(options.wasmPath);\n    cachedModule = module instanceof Promise ? await module : module;\n    isInitialized = true;\n  }\n  return _createDecoderInstance(options.dictionary);\n};\n\n/**\n * Convert BufferSource to Uint8Array\n */\nconst _toUint8Array = (chunk: BufferSource): Uint8Array => {\n  if (chunk instanceof Uint8Array) return chunk;\n  if (ArrayBuffer.isView(chunk))\n    return new Uint8Array(chunk.buffer, chunk.byteOffset, chunk.byteLength);\n  return new Uint8Array(chunk as ArrayBuffer);\n};\n\n\n/**\n * ZstdDecompressionStream\n */\nexport class ZstdDecompressionStream {\n  readonly readable: ReadableStream;\n  readonly writable: WritableStream;\n\n  constructor(options?: ZstdOptions) {\n    let decoder: ZstdDecoder;\n    let idx: number = -1;\n    let dictId: number = 0;\n    let isFirstChunk = true;\n    // A temporary buffer to hold data until the header can be read.\n    let initialBuffer: Uint8Array[] = [];\n    let headerInfo: DZstdState = { d: 0, u: 0, e: -1 };\n    let bytesRead: number = 0\n    let bytesWritten: number = 0\n    let bufLen: number = 0\n    let minRecvSize: number = 262144\n\n    const { readable, writable } = new TransformStream<BufferSource, Uint8Array>({\n      async transform(chunk: BufferSource, controller: TransformStreamDefaultController<Uint8Array>) {\n        const data = _toUint8Array(chunk)\n        bytesRead += data.length\n        initialBuffer.push(data)\n        bufLen++\n        if(bytesRead < 12) {\n          return;\n        } else if(headerInfo.e == -1) {\n          const headerBuffer = new Uint8Array(bytesRead);\n          let offset = 0;\n          for (let i = 0; i < bufLen; i++) {\n            headerBuffer.set(initialBuffer[i], offset);\n            offset += initialBuffer[i].length;\n          }\n          headerInfo = rzfh(headerBuffer) as DZstdState;\n          minRecvSize = Math.max(minRecvSize, headerInfo.e, Math.max(headerInfo.u>>4, 1<<17))\n        }\n        if(bytesRead < minRecvSize || headerInfo.e == -1 ) return;\n        \n        if (decoder) {\n          const result = decoder.decompressStream(data, false).buf;\n          if (result.length > 0) {\n            controller.enqueue(result);\n          }\n          return;\n        }\n        \n\n        try {\n          if (isFirstChunk) {\n            dictId = _getDictId(data);\n            [decoder, idx, dictId] = await _acquireDecoder(dictId, options);\n          }\n          \n          const result = decoder!.decompressStream(data, isFirstChunk).buf;\n          bytesWritten += result.length\n          controller.enqueue(result);\n          isFirstChunk = false;\n        } catch (error) {\n          controller.error(new Error(`Decompression error: ${error}`));\n        }\n      },\n\n      async flush(controller: TransformStreamDefaultController<Uint8Array>) {\n        if(bytesWritten == 0 && bytesRead > 6) {\n          try {\n            const res = await decompressStream(_concatUint8Arrays(initialBuffer, bytesRead), true, options);\n            controller.enqueue(res.buf);\n          } catch (err) {\n            controller.error(new Error(`Decompression error: ${err}`));\n          }\n        } else {\n          if(idx == -1) {\n            decoder?.destroy();\n          } else {\n            _releaseDecoder(idx, dictId);\n          }\n        }\n        controller.terminate();\n      }\n    });\n\n    this.readable = readable;\n    this.writable = writable;\n  }\n}\n\n/**\n * Decompress data completely\n * (Proxies to decompressStream and returns the buf)\n */\nexport const decompress = /* @__PURE__ */ async (\n  input: Uint8Array,\n  options?: ZstdOptions\n): Promise<Uint8Array> => {\n  return (await decompressStream(input, true, options)).buf;\n};\n\n/**\n * Decompress data as a stream (for chunked processing)\n */\nexport const decompressStream = /* @__PURE__ */ async (\n  input: Uint8Array,\n  reset = false,\n  options?: ZstdOptions\n): Promise<StreamResult> => {\n  const dictId = _getDictId(input);\n  const [decoder, idx] = await _acquireDecoder(dictId, options);\n  const result = decoder.decompressStream(input, reset);\n  idx === -1 ? decoder.destroy() : _releaseDecoder(idx, dictId);\n  return result;\n};\n\n/**\n * Decompress data synchronously (when expected size is known)\n */\nexport const decompressSync = /* @__PURE__ */ async (\n  input: Uint8Array,\n  expectedSize?: number,\n  options?: ZstdOptions\n): Promise<Uint8Array> => {\n  const dictId = _getDictId(input);\n  const [decoder, idx] = await _acquireDecoder(dictId, options);\n  const result = decoder.decompressSync(input, expectedSize);\n  idx === -1 ? decoder.destroy() : _releaseDecoder(idx, dictId);\n  return result;\n};\n",
    "import type { DecoderWasmExports, DecoderOptions, StreamResult } from './types.js';\nimport { _concatUint8Arrays } from './shared.js';\nimport { _fss } from './queue.js';\n/**\n * ╔══════════════════════════════════════════════════════════════╗\n * ║                        Memory Layout                         ║\n * ╠══════════════════════════════════════════════════════════════╣\n * ║   0x0000   ┌────────────────────────────────────┐            ║\n * ║            │      Stack Space (8 KB)            │            ║\n * ║   0x2000   ├────────────────────────────────────┤            ║\n * ║            │   ZSTD_DCtx Context (~64 KB)       │            ║\n * ║            │   (Decompression context +         │            ║\n * ║            │    workspace)                      │            ║\n * ║ ~0x12000   ├────────────────────────────────────┤            ║\n * ║            │   Dictionary (optional)            │            ║\n * ║            │   (up to 2 MB)                     │            ║\n * ║            │   (only allocated if provided)     │            ║\n * ║    +2MB    ├────────────────────────────────────┤            ║\n * ║            │  Stream Structs (24 bytes):        │            ║\n * ║            │    ┌─────────────────────────┐     │            ║\n * ║            │    │ ZSTD_inBuffer (12b)     │     │            ║\n * ║            │    │ - srcPtr  (4 bytes)     │     │            ║\n * ║            │    │ - size    (4 bytes)     │     │            ║\n * ║            │    │ - pos     (4 bytes)     │     │            ║\n * ║            │    ├─────────────────────────┤     │            ║\n * ║            │    │ ZSTD_outBuffer (12b)    │     │            ║\n * ║            │    │ - dstPtr  (4 bytes)     │     │            ║\n * ║            │    │ - size    (4 bytes)     │     │            ║\n * ║            │    │ - pos     (4 bytes)     │     │            ║\n * ║            │    └─────────────────────────┘     │            ║\n * ║    +24b    ├────────────────────────────────────┤            ║\n * ║            │    Source Buffer (2 MB)            │            ║\n * ║            │    (Compressed input staging)      │            ║\n * ║    +2MB    ├────────────────────────────────────┤            ║\n * ║            │    Destination Buffer (8.4 MB)     │            ║\n * ║            │    + 1mb margin                    │            ║\n * ║            │  Sized for level 19 compression:   │            ║\n * ║            │  windowSize (8MB) + 3*blockSize    │            ║\n * ║            │  (384KB) + 64 bytes                │            ║\n * ║  +9.4MB    └────────────────────────────────────┘            ║\n * ║                                                              ║\n * ║ Total: ~13.5 MB (with dict), ~11.5 MB (without dict)         ║\n * ╠══════════════════════════════════════════════════════════════╣\n * ║                         Notes                                ║\n * ╠══════════════════════════════════════════════════════════════╣\n * ║ • This memory layout supports decompression of files         ║\n * ║   compressed at any level up to lvl 19                       ║\n * ║                                                              ║\n * ║ • Input/output does NOT have to fit within these buffer      ║\n * ║   limits. As long as user-configured maxSrcSize & maxDstSize ║\n * ║   aren't crossing the limits, we can decompress arbitrarily  ║\n * ║   large files through streaming                              ║\n * ║                                                              ║\n * ║ • For small files that fit in the buffers, we use fast sync  ║\n * ║   decompression. For larger files, we automatically fallback ║\n * ║   to streaming decompression                                 ║\n * ║                                                              ║\n * ║ • Memory is managed primarily from JS by resetting buffer    ║\n * ║   pointers back to dstPtr at every freshly initialized       ║\n * ║   stream, avoiding WASM heap growth                          ║\n * ║                                                              ║\n * ║ • The WASM memory can grow into the JS runtime if needed,    ║\n * ║   but we size the initial allocation to handle most common   ║\n * ║   cases without heap growth needed at all                    ║\n * ╚══════════════════════════════════════════════════════════════╝\n */\n\n\n/**\n *    \n *    https://github.com/facebook/zstd/blob/release/lib/decompress/zstd_decompress.c#L1980\n * \n *    Level 19 memory requirements:\n *\n *  - windowSize:          8 MB     8 * 1024 * 1024 bytes\n * \n *  - 3 * blockSize:     384 KB     3 * 128 KB = 384 KB = 3 * 131072 bytes\n * \n *  - Safety margin:   64 bytes     for fast memcpy functions that may\n *                                  read/write slightly out of bounds\n *\n *    Total Memory = blockSize + (windowSize + 2 * blockSize + 2 * WILDCOPY_OVERLENGTH)\n * \n *\n *    Other relevant sources:\n *      - Zstandard decompressor errata:\n *          https://github.com/facebook/zstd/blob/release/doc/decompressor_errata.md\n *      - Permissiveness / Edge-Cases:\n *          https://github.com/facebook/zstd/blob/release/doc/decompressor_permissive.md\n *      - Zstd manual:\n *          https://facebook.github.io/zstd/zstd_manual.html\n */\n\nconst _MAX_DST_BUF = 9830464;  // 9.37 MB\nconst _MAX_SRC_BUF = 2 * 1024 * 1024;  // 2 MB input buffer\nconst _STREAM_RESULT: StreamResult = { buf: new Uint8Array(0), code: 0, in_offset: 0 };\nclass ZstdDecoder {\n  private _wasm!: WebAssembly.Instance;\n  private _exports!: DecoderWasmExports;\n  private _memory!: WebAssembly.Memory;\n  private _HEAPU8!: Uint8Array;\n  private _HEAPU32!: Uint32Array;\n  \n  private readonly _options: {\n    dictionary?: Uint8Array;\n    maxSrcSize: number;\n    maxDstSize: number;\n  };\n\n  // Memory pointers\n  private _streamInputStructPtr: number = 0;\n  private _streamOutputStructPtr: number = 0;\n  private _ddict: number = 0;\n  private _srcPtr: number = 0;\n  private _dstPtr: number = 0;\n\n  private _bufferDstSize: number = _MAX_DST_BUF;\n  \n  constructor(options: DecoderOptions = {}) {\n    this._options = {\n      dictionary: options.dictionary,\n      maxSrcSize: options.maxSrcSize || 0,\n      maxDstSize: options.maxDstSize || 0\n    };\n  }\n\n  /**\n   * Initialize with a compiled WebAssembly module\n   */\n  init(wasmModule: WebAssembly.Module): ZstdDecoder {\n    this._wasm = new WebAssembly.Instance(wasmModule, { env: {} });;\n    return this._initCommon();\n  }\n\n  /**\n   * Initialize with an existing WebAssembly instance\n   */\n  _initWithInstance(wasmInstance: WebAssembly.Instance, _wasmModule?: WebAssembly.Module): ZstdDecoder {\n    this._wasm = wasmInstance;\n    return this._initCommon();\n  }\n\n  private _initCommon(): ZstdDecoder {\n    this._exports = this._wasm.exports as unknown as DecoderWasmExports;\n    this._memory = (this._wasm.exports).memory as WebAssembly.Memory;\n\n    this._HEAPU8 = new Uint8Array(this._memory.buffer);\n    this._HEAPU32 = new Uint32Array(this._memory.buffer);\n\n    // Reserve space for the streaming buffer structs:\n    // - ZSTD_inBuffer (12 bytes): { srcPtr, size, pos }\n    // - ZSTD_outBuffer (12 bytes): { dstPtr, size, pos }\n    // We'll keep both structs contiguous in memory.\n    // Allocate 24 bytes for both structs in one go\n    this._streamInputStructPtr = this._malloc(24);\n    // Output buffer struct goes after input's 12 bytes. Only 1 malloc at startup\n    this._streamOutputStructPtr = this._streamInputStructPtr + 12;\n\n    this._exports.createDCtx();\n\n    // Initialize dictionary if provided\n    if (this._options.dictionary) {\n      const _dictLen = this._options.dictionary.length\n      if (_dictLen > _MAX_SRC_BUF*2) {\n        throw new Error('dict>2mb max size');\n      }\n      const dictPtr = this._malloc(_dictLen);\n      this._HEAPU8.set(this._options.dictionary as Uint8Array, dictPtr);\n      this._ddict = this._exports.createDict(dictPtr, _dictLen);\n    }\n    this._srcPtr = this._malloc(_MAX_SRC_BUF);\n    this._dstPtr = this._srcPtr + _MAX_SRC_BUF // We don't malloc dst buf. Its where dst buf starts. Zstd will malloc\n    return this;\n  }\n\n  /**\n   * Allocate memory in WASM module\n   */\n  private _malloc(size: number): number {\n    return this._exports.bmalloc(size);\n  }\n\n  /**\n   * Simple API: Decompress a buffer synchronously\n   * Falls back to asynchronous compression if the expected size\n   * is not hinted in advance.\n   * \n   * From measurements taken, it is more efficient to fallback\n   * to streaming than to attempt to infer the expected size from the headers.\n   * \n   * @param compressedData - Compressed data\n   * @param expectedSize - Optional expected decompressed size. If not provided, falls back to streaming.\n   * @returns Decompressed data\n   */\n  decompressSync(compressedData: Uint8Array, expectedSize?: number): Uint8Array {\n    if (!this._exports) throw new Error('module not initialized');\n    \n    const srcSize = compressedData.length;\n    \n    if (srcSize > this._options.maxSrcSize ) {\n      throw new Error(`comp data ${srcSize}b>maxSrcSize lim ${this._options.maxSrcSize}b)`);\n    }\n    \n    // No expected size => Use streaming\n    if(!expectedSize) expectedSize = _fss(compressedData)\n\n    if (!expectedSize || expectedSize > _MAX_DST_BUF || srcSize > _MAX_SRC_BUF) {\n      return this.decompressStream(compressedData, true).buf;\n    }\n    \n    this._HEAPU8.set(compressedData as Uint8Array, this._srcPtr);\n    this._exports.prune_buf(this._dstPtr);\n    const _dstPtr = this._dstPtr\n    const result = this._exports.decompressSync(\n      _dstPtr,\n      this._bufferDstSize,\n      this._srcPtr,\n      srcSize,\n      this._ddict\n    );\n\n    if (result < 0) {\n      throw new Error(`decomp failed err ${result}`);\n    }\n    return this._HEAPU8.slice(_dstPtr, _dstPtr + result);\n  }\n\n\n  /**\n   * Optimized struct write using Uint32Array when properly aligned / (JIT)\n   */\n  private _writeStreamStruct(ptr: number, bufPtr: number, size: number): void {\n    const u32Index = ptr >>> 2;\n    this._HEAPU32[u32Index] = bufPtr;\n    this._HEAPU32[u32Index + 1] = size;\n    this._HEAPU32[u32Index + 2] = 0;\n  }\n  \n  /**\n   * Optimized struct read using Uint32Array\n   */\n  private _readStreamPos(ptr: number): number {\n    return this._HEAPU32[(ptr + 8) >>> 2];\n  }\n\n  /**\n   * Streadming decompression - can be fed chunks incrementally\n   * \n   * @param input - Input chunk\n   * @param reset - Reset stream for new decompression (default: false)\n   * @returns Decompression result with buffer, code, and input offset\n   */\n  decompressStream(input: Uint8Array, reset = false): StreamResult {\n    if (!this._exports) throw new Error('WASM module not initialized');\n    \n    // Reset stream state for new decompression - ZSTD_reset_session_only = 1\n    if (reset) {\n      this._exports.reset();\n\n      if (this._ddict) this._exports.refDict(this._ddict);\n\n      this._exports.prune_buf(this._dstPtr);\n    }\n    let _STREAM_RESULT_OUT = _STREAM_RESULT\n    if (!input || input.length === 0) return _STREAM_RESULT_OUT;\n\n    const output: Uint8Array[] = [];\n    \n    let totalOutputSize = 0;\n    let offset = 0;\n\n    // const 128kb less overhead than adaptive input\n    const suggestedInputSize = 131075; //ZSTD_BLOCKSIZE_MAX + ZSTD_BLOCKHEADERSIZE (131072 + 3)\n\n    // Assuming 4-8x compressability in the average case\n    // Write src buf less.\n    // Let 1mb - 128kb out buf accumulate before we flush it out back to js\n    const dstBufStart = this._srcPtr + 262150 \n    let dstOffset = dstBufStart;\n    let dstMaxBuf = dstBufStart + 655360\n    let lastOut = 0\n    while (offset < input.length) {\n      const toProcess = Math.min(Math.min(input.length - offset, suggestedInputSize), 262150);\n      this._HEAPU8.set((input as Uint8Array).subarray(offset, offset + toProcess), this._srcPtr);\n      \n      this._writeStreamStruct(this._streamInputStructPtr, this._srcPtr, toProcess);\n\n      if(dstOffset == dstBufStart) {\n        this._writeStreamStruct(this._streamOutputStructPtr, dstOffset, 917501);\n      }\n      \n      // Process all data in current block\n      while (this._readStreamPos(this._streamInputStructPtr) < toProcess) {\n        const result = this._exports.decStream(\n          this._streamOutputStructPtr,\n          this._streamInputStructPtr\n        );\n        \n        if (result < 0) throw new Error(`decomp err ${result}`);\n        \n        const outputPos = this._readStreamPos(this._streamOutputStructPtr);\n        \n        totalOutputSize += dstOffset == dstBufStart ? outputPos : (outputPos - lastOut);\n        lastOut = outputPos\n        if (outputPos > 0) {\n\n          dstOffset = dstBufStart + outputPos\n\n          if(dstOffset >= dstMaxBuf) {\n            output.push(this._HEAPU8.slice(dstBufStart, dstOffset));\n            dstOffset = dstBufStart;\n            this._writeStreamStruct(this._streamOutputStructPtr, dstOffset, 917501);\n          }\n          \n          if (totalOutputSize > this._options.maxDstSize) {\n            throw new Error(`decomp size ${totalOutputSize}b>maxDstSize lim ${this._options.maxDstSize}b`);\n          }\n        }\n      }\n      offset += toProcess;\n    }\n    if (dstOffset != dstBufStart) output.push(this._HEAPU8.slice(dstBufStart, dstOffset));\n    _STREAM_RESULT_OUT = {\n      buf: _concatUint8Arrays(output, totalOutputSize),\n      code: 0,\n      in_offset: input.length,\n    };\n    return _STREAM_RESULT_OUT;\n  }\n\n  /**\n   * Clean up ZSTD contexts\n   */\n  destroy(): void {\n    //@ts-expect-error gc.\n    this._ddict = this._srcPtr = this._dstPtr = this._streamInputStructPtr = this._streamOutputStructPtr = this._wasm = this._exports = this._memory = this._HEAPU8 = this._HEAPU32 = null;\n  }\n}\n\nexport default ZstdDecoder;\nexport { ZstdDecoder };\nexport type { DecoderOptions, StreamResult } from './types.js';\n"
  ],
  "mappings": ";AAOO,IAAM,KAAqB,CAAC,GAAe,GAAW,MAAc;AAAA,EACzE,IAAI,IAAI,GAAG,IAAI;AAAA,EACf,MAAO,IAAI,GAAG,EAAE;AAAA,IAAG,KAAK,EAAE,SAAS,KAAK;AAAA,EACxC,OAAO;AAAA;AAGF,IAAM,OAAO,CAAC,QAA4B;AAAA,EAC/C,MAAM,MAAM,IAAI;AAAA,EAChB,MAAM,KAAM,OAAO,IAAK,GAAG,KAAK,MAAM,GAAG,MAAM,OAAO;AAAA,EAEtD,MAAM,MAAM,GAAG,KAAM,IAAI,KAAM,MAAM,IAAI,IAAI,IAAI,MAAO,KAAK,MAAO,EAAE,KAAM,OAAO,KAAM;AAAA,EACzF,OAAO;AAAA;;;ACXF,IAAM,YAAY;AAAA,EACvB,SAAS;AAAA,EACT,aAAa;AAAA,IACX,YAAY,KAAK,OAAO;AAAA,IACxB,YAAY,MAAM,OAAO;AAAA,EAC3B;AAAA,EACA,cAAc,CAAC;AACjB;AAGA,IAAM,eAAe,IAAI;AAEzB,IAAM,YAAY,IAAI;AAItB,IAAM,qBAAqB,IAAI;AA6BxB,SAAS,kBAAkB,CAAC,QAAsB,IAAwB;AAAA,EAC/E,IAAI,OAAO,WAAW;AAAA,IAAG,OAAO,OAAO;AAAA,EACvC,MAAM,MAAM,IAAI,WAAW,EAAE;AAAA,EAC7B,SAAS,IAAI,GAAG,IAAI,EAAG,IAAI,OAAO,QAAQ,EAAE,GAAG;AAAA,IAC7C,MAAM,MAAM,OAAO;AAAA,IACnB,IAAI,IAAI,KAAK,CAAC;AAAA,IACd,KAAK,IAAI;AAAA,EACX;AAAA,EACA,OAAO;AAAA;;;ACiCT,IAAM,eAAe;AACrB,IAAM,eAAe,IAAI,OAAO;AAChC,IAAM,iBAA+B,EAAE,KAAK,IAAI,WAAW,CAAC,GAAG,MAAM,GAAG,WAAW,EAAE;AAAA;AACrF,MAAM,YAAY;AAAA,EACR;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EAES;AAAA,EAOT,wBAAgC;AAAA,EAChC,yBAAiC;AAAA,EACjC,SAAiB;AAAA,EACjB,UAAkB;AAAA,EAClB,UAAkB;AAAA,EAElB,iBAAyB;AAAA,EAEjC,WAAW,CAAC,UAA0B,CAAC,GAAG;AAAA,IACxC,KAAK,WAAW;AAAA,MACd,YAAY,QAAQ;AAAA,MACpB,YAAY,QAAQ,cAAc;AAAA,MAClC,YAAY,QAAQ,cAAc;AAAA,IACpC;AAAA;AAAA,EAMF,IAAI,CAAC,YAA6C;AAAA,IAChD,KAAK,QAAQ,IAAI,YAAY,SAAS,YAAY,EAAE,KAAK,CAAC,EAAE,CAAC;AAAA,IAC7D,OAAO,KAAK,YAAY;AAAA;AAAA,EAM1B,iBAAiB,CAAC,cAAoC,aAA+C;AAAA,IACnG,KAAK,QAAQ;AAAA,IACb,OAAO,KAAK,YAAY;AAAA;AAAA,EAGlB,WAAW,GAAgB;AAAA,IACjC,KAAK,WAAW,KAAK,MAAM;AAAA,IAC3B,KAAK,UAAW,KAAK,MAAM,QAAS;AAAA,IAEpC,KAAK,UAAU,IAAI,WAAW,KAAK,QAAQ,MAAM;AAAA,IACjD,KAAK,WAAW,IAAI,YAAY,KAAK,QAAQ,MAAM;AAAA,IAOnD,KAAK,wBAAwB,KAAK,QAAQ,EAAE;AAAA,IAE5C,KAAK,yBAAyB,KAAK,wBAAwB;AAAA,IAE3D,KAAK,SAAS,WAAW;AAAA,IAGzB,IAAI,KAAK,SAAS,YAAY;AAAA,MAC5B,MAAM,WAAW,KAAK,SAAS,WAAW;AAAA,MAC1C,IAAI,WAAW,eAAa,GAAG;AAAA,QAC7B,MAAM,IAAI,MAAM,mBAAmB;AAAA,MACrC;AAAA,MACA,MAAM,UAAU,KAAK,QAAQ,QAAQ;AAAA,MACrC,KAAK,QAAQ,IAAI,KAAK,SAAS,YAA0B,OAAO;AAAA,MAChE,KAAK,SAAS,KAAK,SAAS,WAAW,SAAS,QAAQ;AAAA,IAC1D;AAAA,IACA,KAAK,UAAU,KAAK,QAAQ,YAAY;AAAA,IACxC,KAAK,UAAU,KAAK,UAAU;AAAA,IAC9B,OAAO;AAAA;AAAA,EAMD,OAAO,CAAC,MAAsB;AAAA,IACpC,OAAO,KAAK,SAAS,QAAQ,IAAI;AAAA;AAAA,EAenC,cAAc,CAAC,gBAA4B,cAAmC;AAAA,IAC5E,IAAI,CAAC,KAAK;AAAA,MAAU,MAAM,IAAI,MAAM,wBAAwB;AAAA,IAE5D,MAAM,UAAU,eAAe;AAAA,IAE/B,IAAI,UAAU,KAAK,SAAS,YAAa;AAAA,MACvC,MAAM,IAAI,MAAM,aAAa,2BAA2B,KAAK,SAAS,cAAc;AAAA,IACtF;AAAA,IAGA,IAAG,CAAC;AAAA,MAAc,eAAe,KAAK,cAAc;AAAA,IAEpD,IAAI,CAAC,gBAAgB,eAAe,gBAAgB,UAAU,cAAc;AAAA,MAC1E,OAAO,KAAK,iBAAiB,gBAAgB,IAAI,EAAE;AAAA,IACrD;AAAA,IAEA,KAAK,QAAQ,IAAI,gBAA8B,KAAK,OAAO;AAAA,IAC3D,KAAK,SAAS,UAAU,KAAK,OAAO;AAAA,IACpC,MAAM,UAAU,KAAK;AAAA,IACrB,MAAM,SAAS,KAAK,SAAS,eAC3B,SACA,KAAK,gBACL,KAAK,SACL,SACA,KAAK,MACP;AAAA,IAEA,IAAI,SAAS,GAAG;AAAA,MACd,MAAM,IAAI,MAAM,qBAAqB,QAAQ;AAAA,IAC/C;AAAA,IACA,OAAO,KAAK,QAAQ,MAAM,SAAS,UAAU,MAAM;AAAA;AAAA,EAO7C,kBAAkB,CAAC,KAAa,QAAgB,MAAoB;AAAA,IAC1E,MAAM,WAAW,QAAQ;AAAA,IACzB,KAAK,SAAS,YAAY;AAAA,IAC1B,KAAK,SAAS,WAAW,KAAK;AAAA,IAC9B,KAAK,SAAS,WAAW,KAAK;AAAA;AAAA,EAMxB,cAAc,CAAC,KAAqB;AAAA,IAC1C,OAAO,KAAK,SAAU,MAAM,MAAO;AAAA;AAAA,EAUrC,gBAAgB,CAAC,OAAmB,QAAQ,OAAqB;AAAA,IAC/D,IAAI,CAAC,KAAK;AAAA,MAAU,MAAM,IAAI,MAAM,6BAA6B;AAAA,IAGjE,IAAI,OAAO;AAAA,MACT,KAAK,SAAS,MAAM;AAAA,MAEpB,IAAI,KAAK;AAAA,QAAQ,KAAK,SAAS,QAAQ,KAAK,MAAM;AAAA,MAElD,KAAK,SAAS,UAAU,KAAK,OAAO;AAAA,IACtC;AAAA,IACA,IAAI,qBAAqB;AAAA,IACzB,IAAI,CAAC,SAAS,MAAM,WAAW;AAAA,MAAG,OAAO;AAAA,IAEzC,MAAM,SAAuB,CAAC;AAAA,IAE9B,IAAI,kBAAkB;AAAA,IACtB,IAAI,SAAS;AAAA,IAGb,MAAM,qBAAqB;AAAA,IAK3B,MAAM,cAAc,KAAK,UAAU;AAAA,IACnC,IAAI,YAAY;AAAA,IAChB,IAAI,YAAY,cAAc;AAAA,IAC9B,IAAI,UAAU;AAAA,IACd,OAAO,SAAS,MAAM,QAAQ;AAAA,MAC5B,MAAM,YAAY,KAAK,IAAI,KAAK,IAAI,MAAM,SAAS,QAAQ,kBAAkB,GAAG,MAAM;AAAA,MACtF,KAAK,QAAQ,IAAK,MAAqB,SAAS,QAAQ,SAAS,SAAS,GAAG,KAAK,OAAO;AAAA,MAEzF,KAAK,mBAAmB,KAAK,uBAAuB,KAAK,SAAS,SAAS;AAAA,MAE3E,IAAG,aAAa,aAAa;AAAA,QAC3B,KAAK,mBAAmB,KAAK,wBAAwB,WAAW,MAAM;AAAA,MACxE;AAAA,MAGA,OAAO,KAAK,eAAe,KAAK,qBAAqB,IAAI,WAAW;AAAA,QAClE,MAAM,SAAS,KAAK,SAAS,UAC3B,KAAK,wBACL,KAAK,qBACP;AAAA,QAEA,IAAI,SAAS;AAAA,UAAG,MAAM,IAAI,MAAM,cAAc,QAAQ;AAAA,QAEtD,MAAM,YAAY,KAAK,eAAe,KAAK,sBAAsB;AAAA,QAEjE,mBAAmB,aAAa,cAAc,YAAa,YAAY;AAAA,QACvE,UAAU;AAAA,QACV,IAAI,YAAY,GAAG;AAAA,UAEjB,YAAY,cAAc;AAAA,UAE1B,IAAG,aAAa,WAAW;AAAA,YACzB,OAAO,KAAK,KAAK,QAAQ,MAAM,aAAa,SAAS,CAAC;AAAA,YACtD,YAAY;AAAA,YACZ,KAAK,mBAAmB,KAAK,wBAAwB,WAAW,MAAM;AAAA,UACxE;AAAA,UAEA,IAAI,kBAAkB,KAAK,SAAS,YAAY;AAAA,YAC9C,MAAM,IAAI,MAAM,eAAe,mCAAmC,KAAK,SAAS,aAAa;AAAA,UAC/F;AAAA,QACF;AAAA,MACF;AAAA,MACA,UAAU;AAAA,IACZ;AAAA,IACA,IAAI,aAAa;AAAA,MAAa,OAAO,KAAK,KAAK,QAAQ,MAAM,aAAa,SAAS,CAAC;AAAA,IACpF,qBAAqB;AAAA,MACnB,KAAK,mBAAmB,QAAQ,eAAe;AAAA,MAC/C,MAAM;AAAA,MACN,WAAW,MAAM;AAAA,IACnB;AAAA,IACA,OAAO;AAAA;AAAA,EAMT,OAAO,GAAS;AAAA,IAEd,KAAK,SAAS,KAAK,UAAU,KAAK,UAAU,KAAK,wBAAwB,KAAK,yBAAyB,KAAK,QAAQ,KAAK,WAAW,KAAK,UAAU,KAAK,UAAU,KAAK,WAAW;AAAA;AAEtL;AAEA,IAAe;",
  "debugId": "67E75C23ADFF02E764756E2164756E21",
  "names": []
}